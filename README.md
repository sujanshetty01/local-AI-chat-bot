# ğŸ¤– Local AI Chatbot with CSV/JSON Upload

A fully local AI chatbot system built using **Streamlit**, **FastAPI**, **Ollama (Gemma3/Mistral)**, and **SQLite/PostgreSQL**, allowing users to upload structured data (CSV/JSON), embed it locally, and ask natural language questions to get contextual answers.

---

## ğŸš€ Features

* Upload and parse CSV/JSON datasets.
* Embed data locally using `nomic-embed-text`.
* Ask natural language questions about the dataset.
* Uses **Ollama** for running open-source LLMs (e.g., Gemma3) locally.
* Streamlit frontend for easy user interaction.
* FastAPI backend for processing and embedding.
* Lightweight and containerized with Docker.

---

## ğŸ“ Folder Structure

```
local-AI-chat-bot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI server
â”‚   â”œâ”€â”€ database.py          # SQLite or PostgreSQL logic
â”‚   â””â”€â”€ embed_utils.py       # Embedding & retrieval logic
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py               # Streamlit UI
â”œâ”€â”€ data/                    # Uploaded CSV/JSON files
â”œâ”€â”€ models/                  # Ollama model configuration
â”œâ”€â”€ Dockerfile               # For containerizing the app
â”œâ”€â”€ docker-compose.yml       # Run frontend & backend together
â”œâ”€â”€ .env                     # Config (DB paths, API keys)
â””â”€â”€ requirements.txt         # Python dependencies
```

---

## ğŸ› ï¸ Requirements

* Python 3.10+
* Ollama (running locally)
* Docker & Docker Compose (optional but recommended)

Install Python dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸ§  Ollama Setup

Install and start Ollama:

```bash
ollama run gemma3
```

Or pull another model:

```bash
ollama pull mistral
```

> Ensure Ollama is running on `http://localhost:11434`

---

## ğŸš¦ How to Run

### ğŸ”¹ Backend (FastAPI)

```bash
cd backend
uvicorn main:app --reload --port 8000
```

### ğŸ”¹ Frontend (Streamlit)

```bash
cd frontend
streamlit run app.py
```

> Update `.env` files or hardcoded paths to match your environment.

---

## ğŸ³ Run with Docker (Optional)

Build and run using Docker Compose:

```bash
docker compose up --build
```

---

## ğŸ’¡ Example Use Case

1. Upload a `flights.csv` or `cars.json`.
2. Ask questions like:

   * "What is the average price of the cars?"
   * "Which airline has the longest average flight time?"
3. The model gives intelligent, local responses without internet.

---

## âœ… To-Do

* [x] CSV/JSON support
* [x] Local vector embeddings
* [x] Ollama LLM integration
* [ ] File delete and refresh support
* [ ] Export chat history
* [ ] Authentication (admin vs guest)

---

## ğŸ§‘â€ğŸ’» Author

**Sujan S Shetty**
GitHub: [@sujanshetty01](https://github.com/sujanshetty01)

---

## ğŸ“œ License

This project is licensed under the MIT License.
